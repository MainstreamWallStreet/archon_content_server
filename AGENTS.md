# Project Agents.md Guide for AI Agents

This Agents.md file provides comprehensive guidance for AI agents working with the Zergling FastAPI server template codebase.

## Project Structure for AI Agent Navigation

- `/src`: Source code that AI agents should analyze and modify
  - `/api.py`: Main FastAPI application with route handlers
  - `/config.py`: Configuration management and environment variables
  - `/database.py`: Database connection and session management
  - `/gcs_store.py`: Google Cloud Storage data store implementation
  - `/models.py`: Pydantic models for data validation
  - `/scheduler.py`: Background task scheduler
- `/tests`: Test files that AI agents should maintain and extend
  - `/test_api.py`: API endpoint tests
  - `/test_config.py`: Configuration tests
  - `/test_database.py`: Database tests
  - `/test_models.py`: Model validation tests
- `/infra`: Terraform infrastructure as code
  - `/main.tf`: Main infrastructure configuration
  - `/variables.tf`: Variable definitions
  - `/outputs.tf`: Output values
  - `/backend.tf`: Terraform state configuration
- `/scripts`: Utility scripts for deployment and testing
  - `/test_deployment.sh`: Manual deployment testing
  - `/test_api.sh`: API testing script
  - `/setup_zergling.sh`: Initial setup script
- `/docs`: Documentation files
  - `/ci-cd.md`: CI/CD pipeline documentation
  - `/infra/README.md`: Infrastructure documentation
  - `/infra/quick-reference.md`: Quick reference guide
- `.github/workflows`: GitHub Actions workflows
  - `/pr-test.yml`: Pull request testing workflow
  - `/deploy.yml`: Deployment workflow

## Coding Conventions for AI Agents

### General Conventions for Agents.md Implementation

- Use Python 3.11+ for all new code generated by AI agents
- AI agents should follow the existing code style in each file
- Agents.md requires meaningful variable and function names in AI agent output
- AI agents should add type hints for all functions and variables
- AI agents should add docstrings for all public functions and classes
- AI agents should use async/await patterns where appropriate
- AI agents should follow PEP 8 style guidelines

### FastAPI Guidelines for AI Agents

- AI agents should use FastAPI decorators for route definitions
- Keep route handlers generated by AI agents focused and single-purpose
- AI agents must use Pydantic models for request/response validation
- AI agents should implement proper error handling with HTTP status codes
- AI agents should add API documentation using FastAPI's automatic docs
- AI agents must use dependency injection for shared resources

### Testing Standards for AI Agents

- AI agents should write tests for all new functionality
- Use pytest for all test implementations
- AI agents should use async test functions when testing async code
- AI agents should mock external dependencies (GCS, databases, etc.)
- AI agents should achieve high test coverage (aim for 90%+)
- AI agents should use descriptive test names that explain the scenario

### Infrastructure Guidelines for AI Agents

- AI agents should not modify Terraform files without understanding the infrastructure
- AI agents should follow existing naming conventions in Terraform
- AI agents should ensure all Terraform resources have proper tags
- AI agents should maintain security best practices in infrastructure code
- AI agents should add proper documentation for new infrastructure components

## Testing Requirements for AI Agents

AI agents should run tests with the following commands:

```bash
# Run all tests
pytest

# Run tests with coverage
pytest --cov=src

# Run specific test file
pytest tests/test_api.py

# Run tests with verbose output
pytest -v

# Run tests and generate coverage report
pytest --cov=src --cov-report=html
```

## Pull Request Guidelines for AI Agents

When AI agents help create a PR, please ensure it:

1. Includes a clear description of the changes as guided by Agents.md
2. References any related issues that AI agents are addressing
3. Ensures all tests pass for code generated by AI agents
4. Includes API documentation updates for new endpoints
5. Updates relevant documentation files
6. Keeps PRs focused on a single concern as specified in Agents.md
7. Follows conventional commit message format

## Programmatic Checks for AI Agents

Before submitting changes generated by AI agents, run:

```bash
# Type checking
mypy src/

# Linting
flake8 src/

# Formatting check
black --check src/

# Run all tests
pytest

# Build Docker image locally
docker build -t zergling-test .
```

All checks must pass before AI agent generated code can be merged. Agents.md helps ensure AI agents follow these requirements.

## API Development Guidelines for AI Agents

### Adding New Endpoints

1. **Define Pydantic models** in `src/models.py` for request/response validation
2. **Add route handlers** in `src/api.py` with proper decorators
3. **Write comprehensive tests** in `tests/test_api.py`
4. **Update API documentation** with proper descriptions
5. **Add authentication** using the existing API key middleware
6. **Implement error handling** with appropriate HTTP status codes

### Data Storage Guidelines

- AI agents should use the existing GCS store interface in `src/gcs_store.py`
- AI agents should implement proper error handling for storage operations
- AI agents should use JSON serialization for data persistence
- AI agents should follow the existing data structure patterns

### Background Tasks

- AI agents should use the existing scheduler in `src/scheduler.py`
- AI agents should implement proper error handling for background tasks
- AI agents should add logging for task execution
- AI agents should ensure tasks are idempotent and safe to retry

## Security Guidelines for AI Agents

- AI agents must never hardcode secrets or sensitive information
- AI agents should use environment variables for configuration
- AI agents should validate all input data using Pydantic models
- AI agents should implement proper authentication for all endpoints
- AI agents should follow the principle of least privilege
- AI agents should add proper logging for security events

## Deployment Guidelines for AI Agents

- AI agents should not modify deployment configurations without understanding the pipeline
- AI agents should ensure new dependencies are added to `requirements.txt`
- AI agents should test Docker builds locally before deployment
- AI agents should verify that new environment variables are properly configured
- AI agents should ensure health checks pass for new functionality

## Error Handling Standards for AI Agents

- AI agents should use FastAPI's HTTPException for API errors
- AI agents should implement proper logging for all errors
- AI agents should provide meaningful error messages to users
- AI agents should handle edge cases gracefully
- AI agents should implement retry logic for transient failures

## Documentation Requirements for AI Agents

- AI agents should update README.md for user-facing changes
- AI agents should update relevant documentation in `/docs/`
- AI agents should add inline comments for complex logic
- AI agents should document API changes in code comments
- AI agents should maintain up-to-date type hints

## Performance Guidelines for AI Agents

- AI agents should use async operations where appropriate
- AI agents should implement proper connection pooling
- AI agents should use efficient data structures and algorithms
- AI agents should minimize database queries and external API calls
- AI agents should implement caching where beneficial
- AI agents should profile code for performance bottlenecks

## Monitoring and Observability

- AI agents should add structured logging for all operations
- AI agents should implement proper metrics and health checks
- AI agents should add error tracking and alerting
- AI agents should ensure logs are searchable and actionable
- AI agents should implement proper request tracing

## Code Review Checklist for AI Agents

Before submitting code, AI agents should verify:

- [ ] All tests pass
- [ ] Type checking passes
- [ ] Linting passes
- [ ] Code is properly formatted
- [ ] Documentation is updated
- [ ] Security considerations are addressed
- [ ] Performance implications are considered
- [ ] Error handling is implemented
- [ ] Logging is appropriate
- [ ] API documentation is accurate 